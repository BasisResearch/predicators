# Use VLM to propose predicates.
---
APPROACHES:
  learn_all:
    NAME: "oracle"
    # NAME: "grammar_search_invention"
    FLAGS: []
ENVS:
  stick_button:
    # NAME: "stick_button"
    # NAME: "stick_button_move"
    # NAME: "cover_place_hard"
    # NAME: "blocks"
    # NAME: "cover_multistep_options"
    # NAME: "doors"
    # NAME: "painting"
    # NAME: "tools"
    NAME: "coffee"
    # NAME: "sticky_table"
    # NAME: "burger"
    # NAME: "pybullet_blocks"
    # NAME: "pybullet_coffee"
ARGS: 
  []
  # - "debug"
  # - "rgb_observation" # stick_button doesn't support rendering
  # - "make_failure_videos"
  # - "make_test_videos"
  # - "make_segmented_demo_videos"
  # - "make_demo_videos" 
  # - "use_gui"
FLAGS:
  num_train_tasks: 5
  num_test_tasks: 20
  option_learner: no_learning # include all options by flagging no learning
  kitchen_use_perfect_samplers: True
  # included_options: "HandPressButton"
  # stick_button_button_position: "only_bottom"
  # stick_button_button_position: "only_top"
  # bilevel_plan_without_sim: True
  # excluded_predicates: "all"
  sesame_max_samples_per_step: 10
  min_perc_data_for_nsrt: 1
  segmenter: "contacts"
  neural_gaus_regressor_max_itr: 50000
  timeout: 300
  pybullet_camera_width: 900
  pybullet_camera_height: 900
  video_fps: 20
  # sesame_max_skeletons_optimized: 200

  rgb_observation: False
  save_nsp_image_patch_before_query: True
  vlm_model_name: "gemini-1.5-flash"
  # vlm_model_name: "gpt-4o"
  vlm_temperature: 0
  vlm_use_chat_mode: True
  sesame_check_expected_atoms: False
  query_vlm_for_each_assertion: False
  query_vlm_for_each_predicate: False
  llm_openai_max_response_tokens: 4096


START_SEED: 2
NUM_SEEDS: 1
...
