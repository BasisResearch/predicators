# Config file for generating the mara_bench videos
# Excample run: 
#    python scripts/local/launch_simp.py -c mara_bench.yaml
---
APPROACHES:
  # oracle:
  #   NAME: "oracle_process_planning"
  #   FLAGS:
  #     boil_use_constant_delay: True
  #     # boil_use_normal_delay: True
  #     demonstrator: "oracle_process_planning"
  param_learning:
    NAME: "param_learning_process_planning"
    ARGS:
      - "load_data"
    FLAGS:
      # boil_use_constant_delay: True
      demonstrator: "oracle_process_planning"
      # This following is needed to generate a successful demo trajectory, or 
      # else the demo collection will fail with an option plan exhausted error.
      terminate_on_goal_reached: False
      terminate_on_goal_reached_and_option_terminated: True
      boil_use_normal_delay: True
  # offline_model_learning:
  #   # This can learn the JugFilled and WaterBoiled process but not spill.
  #   NAME: "process_learning_and_planning"
  #   ARGS:
  #     - "load_data"
  #   FLAGS:
  #     demonstrator: "oracle_process_planning"
  #     # This following is needed to generate a successful demo trajectory, or 
  #     # else the demo collection will fail with an option plan exhausted error.
  #     strips_learner: "llm"
  #     find_best_matching_pnad_skip_if_effect_not_subset: False
  #     exogenous_process_learner: "cluster_and_llm_select"
  #     # To have demos to stop when option terminates.
  #     terminate_on_goal_reached: False
  #     terminate_on_goal_reached_and_option_terminated: True
  #     only_learn_exogenous_processes: True
  # online_model_learning:
  #   # This can learn the JugFilled, WaterBoiled and WaterSpilled process.
  #   NAME: "online_process_learning_and_planning"
  #   ARGS:
  #     - "load_data"
  #   FLAGS:
  #     # boil_use_constant_delay: True
  #     demonstrator: "oracle_process_planning"
  #     explorer: "exploit_planning"
  #     online_nsrt_learning_requests_per_cycle: 1  # just 1 for now
  #     max_num_steps_interaction_request: 500
  #     # This following is needed to generate a successful demo trajectory, or 
  #     # else the demo collection will fail with an option plan exhausted error.
  #     strips_learner: "llm"
  #     find_best_matching_pnad_skip_if_effect_not_subset: False
  #     exogenous_process_learner: "cluster_and_llm_select"
  #     # To have demos to stop when option terminates.
  #     terminate_on_goal_reached: False
  #     terminate_on_goal_reached_and_option_terminated: True
  #     only_learn_exogenous_processes: True
  #     online_learning_early_stopping: True
  #     num_online_learning_cycles: 1
  # predicate_invention:
  #   NAME: "online_predicate_invention_and_process_planning"
  #   ARGS:
  #     - "load_data"
  #   FLAGS:
  #     # boil_goal: "task_completed" # This option isn't fully ready because
  #       # with the current only_learn_exogenous_processes setting, it won't try
  #       # to learn the precondition for the DeclareComplete option.
  #     boil_goal: "human_happy" # Can also be "task_completed", "simple"
  #     excluded_predicates: "NoWaterSpilled,WaterBoiled,JugFilled,JugNotFilled,JugNotAtFaucetOrAtFaucetAndFilled"
  #     # boil_use_constant_delay: True
  #     demonstrator: "oracle_process_planning"
  #     explorer: "exploit_planning"
  #     online_nsrt_learning_requests_per_cycle: 1  # just 1 for now
  #     max_num_steps_interaction_request: 300 # 300 should be enough
  #     # This following is needed to generate a successful demo trajectory, or 
  #     # else the demo collection will fail with an option plan exhausted error.
  #     strips_learner: "llm"
  #     find_best_matching_pnad_skip_if_effect_not_subset: False
  #     # exogenous_process_learner: "cluster_and_llm_select"
  #     # exogenous_process_learner: "cluster_and_search_process_learner"
  #     exogenous_process_learner: "cluster_and_inverse_planning"
  #     exogenous_process_learner_do_intersect: True
  #     process_learner_check_false_positives: False
  #     # To have demos to stop when option terminates.
  #     terminate_on_goal_reached: False
  #     terminate_on_goal_reached_and_option_terminated: True
  #     only_learn_exogenous_processes: True
  #     online_learning_early_stopping: True
  #     # pause_after_process_learning_for_inspection: True
  #     num_online_learning_cycles: 20
  #     rgb_observation: False # for visual predicators
  #     boil_use_constant_delay: True
  #     # Testing predicate invention:
  #     vlm_predicator_oracle_base_predicates: True
  #     vlm_predicator_oracle_learned_predicates: True
  #     vlm_predicator_use_grammar: False
  #     grammar_search_grammar_use_single_feature: False
  #     grammar_search_grammar_use_skip_grammar: False
  #     grammar_search_grammar_includes_negation: True
  #     grammar_search_grammar_includes_foralls: False
  #     grammar_search_prune_redundant_preds: False
  #     grammar_search_search_algorithm: "gbfs"
  #     grammar_search_task_planning_timeout: 0.5
  #     learnable_delay_distribution: "constant" # "constant", "cmp", "normal"
  #     bilevel_planning_explorer_enumerate_plans: True
  #     online_nsrt_learning_requests_per_task: 8 # 2
  #     grammar_search_expected_nodes_optimal_demo_prob: 0.5
  #     cluster_and_inverse_planning_candidates: "top_consistent"
  #     # cluster_and_inverse_planning_top_consistent_method: "top_n"
  #     cluster_and_inverse_planning_top_consistent_method: "top_p_percent"
  #     # cluster_and_inverse_planning_top_consistent_method: "threshold"
  #     cluster_and_inverse_planning_top_p_percent: 4
  #     cluster_and_inverse_planning_top_n: 10
  #     exploit_bilevel_planning_explorer_fallback_explorer: "RandomNSRTs"

ENVS:
  # cover:
  #   NAME: "pybullet_cover"
  # cover_cf:c
  #   NAME: "pybullet_cover"
  #   FLAGS:
  #     cover_blocks_change_color_when_cover: True
  # blocks:
  #   NAME: "pybullet_blocks"
  # blocks_cf:
  #   NAME: "pybullet_blocks"
  #   FLAGS:
  #     blocks_high_towers_are_unstable: True
  # coffee:
  #   NAME: "pybullet_coffee"
  #   FLAGS:
  #     coffee_rotated_jug_ratio: 0
  #     sesame_check_expected_atoms: False
  #     coffee_machine_have_light_bar: False
  #     coffee_move_back_after_place_and_push: True
  #     coffee_machine_has_plug: True
  #     option_model_terminate_on_repeat: False
  #     coffee_use_pixelated_jug: True
  #     pybullet_ik_validate: False
  #     sesame_max_skeletons_optimized: 1
  #     max_num_steps_option_rollout: 100
  # coffee_cf:
  #   NAME: "pybullet_coffee"
  #   FLAGS:
  #     coffee_plug_break_after_plugged_in: True
  #     coffee_rotated_jug_ratio: 0
  #     sesame_check_expected_atoms: False
  #     coffee_machine_have_light_bar: False
  #     coffee_move_back_after_place_and_push: True
  #     coffee_machine_has_plug: True
  #     option_model_terminate_on_repeat: False
  #     coffee_use_pixelated_jug: True
  #     pybullet_ik_validate: False
  #     sesame_max_skeletons_optimized: 1
  #     max_num_steps_option_rollout: 100
  # balance:
  #   NAME: "pybullet_balance"
  #   FLAGS:
  #     sesame_task_planning_heuristic: "goal_count"
  #     sesame_check_expected_atoms: False
  #     pybullet_ik_validate: False
  # balance_cf:
  #   NAME: "pybullet_balance"
  #   FLAGS:
  #     balance_wierd_balance: True
  #     sesame_task_planning_heuristic: "goal_count"
  #     sesame_check_expected_atoms: False
  #     pybullet_ik_validate: False
  # grow:
  #   NAME: "pybullet_grow"
  #   FLAGS:
  #     pybullet_ik_validate: False
  #     coffee_use_pixelated_jug: True
  #     max_num_steps_option_rollout: 50
  # grow_cf:
  #   NAME: "pybullet_grow"
  #   FLAGS:
  #     grow_plant_same_color_as_cup: True
  #     pybullet_ik_validate: False
  #     coffee_use_pixelated_jug: True
  #     max_num_steps_option_rollout: 50
  # circuit:
  #   NAME: "pybullet_circuit"
  #   FLAGS:
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     terminate_on_goal_reached: False
  #     pybullet_ik_validate: False
  # circuit_cf:
  #   NAME: "pybullet_circuit"
  #   FLAGS:
  #     circuit_light_doesnt_need_battery: True
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     terminate_on_goal_reached: False
  # float:
  #   NAME: "pybullet_float"
  #   FLAGS:
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     pybullet_ik_validate: False
  #     option_model_terminate_on_repeat: False
  # float_cf:
  #   NAME: "pybullet_float"
  #   FLAGS:
  #     float_water_level_doesnt_raise: True
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     pybullet_ik_validate: False
  #     option_model_terminate_on_repeat: False
  # domino:
  #   NAME: "pybullet_domino"
  #   ARGS:
  #     - "video_not_break_on_exception"
  #   FLAGS:
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     horizon: 60
  #     pybullet_ik_validate: False
  # domino_cf:
  #   NAME: "pybullet_domino"
  #   ARGS:
  #     - "video_not_break_on_exception"
  #   FLAGS:
  #     domino_some_dominoes_are_connected: True
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     horizon: 60
  #     pybullet_ik_validate: False
  # laser:
  #   NAME: "pybullet_laser"
  #   FLAGS:
  #     bilevel_plan_without_sim: True
  #     laser_use_debug_line_for_beams: False
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     pybullet_ik_validate: False
  # laser_cf:
  #   NAME: "pybullet_laser"
  #   FLAGS:
  #     laser_zero_reflection_angle: True
  #     bilevel_plan_without_sim: True
  #     laser_use_debug_line_for_beams: False
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     pybullet_ik_validate: False
  # ants:
  #   NAME: "pybullet_ants"
  #   FLAGS:
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     pybullet_ik_validate: False
  #     terminate_on_goal_reached: False
  # ants_cf:
  #   NAME: "pybullet_ants"
  #   FLAGS:
  #     ants_ants_attracted_to_points: True
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     pybullet_ik_validate: False
  #     terminate_on_goal_reached: False
  # fan:
  #   NAME: "pybullet_fan"
  #   FLAGS:
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     terminate_on_goal_reached: False
  #     pybullet_ik_validate: False
  # fan_cf:
  #   NAME: "pybullet_fan"
  #   FLAGS:
  #     fan_fans_blow_opposite_direction: True
  #     sesame_max_skeletons_optimized: 1
  #     sesame_check_expected_atoms: False
  #     terminate_on_goal_reached: False
  #     pybullet_ik_validate: False
  boil:
    NAME: "pybullet_boil"
    FLAGS:
      pybullet_ik_validate: False
      max_num_steps_option_rollout: 50
      bilevel_plan_without_sim: True
      horizon: 300 # 300 should be enough, 50 is good during dev
ARGS:
  - "debug"
  # - "use_gui"
  # - "make_demo_videos"
  # - "make_failure_videos"
  # - "make_test_videos"
  # - "make_demo_images"  # support images
  # - "make_failure_images"  # query images
  # - "make_test_images"  # query images
  # - "save_atoms"
FLAGS:
  # This is particularly useful in some envs. In blocks with high towers are
  # unstable, this is useful to capture the unstability and to avoid force from
  # the prev. episode to affect the current episode.

  # A successful demo needs this to be True, or else it will get an option plan
  # exhausted error from the option_policy. 
  # When do we need this to be False? Was it in cases when we wanted to generate
  # a more complete video?
  pretrained_model_service_provider: "openai" # "openrouter" or "openai"
  llm_model_name: "gpt-4.1" # "gpt-4.1", "gpt-4o"
  llm_openai_max_response_tokens: 2000
  terminate_on_goal_reached: False
  num_train_tasks: 1
  num_test_tasks: 1
  video_fps: 20
  pybullet_camera_height: 900
  pybullet_camera_width: 900
  use_counterfactual_dataset_path_name: True
  # use_classification_problem_setting: False # This decides the entry point
  keep_failed_demos: True
  planning_filter_unreachable_nsrt: False
  planning_check_dr_reachable: False
  sesame_task_planning_heuristic: 'goal_count'
  timeout: 60
  log: 'logs/'
START_SEED: 0
NUM_SEEDS: 1