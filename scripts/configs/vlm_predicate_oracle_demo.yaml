# Use VLM to propose predicates.
---
APPROACHES:
  learn_all:
    NAME: "oracle"
    # NAME: "grammar_search_invention"
    FLAGS: []
ENVS:
  stick_button:
    # NAME: "stick_button"
    # NAME: "stick_button_move"
    # NAME: "cover_place_hard"
    # NAME: "blocks"
    # NAME: "cover_multistep_options"
    # NAME: "doors"
    # NAME: "painting"
    # NAME: "tools"
    # NAME: "coffee"
    # NAME: "sticky_table"
    NAME: "pybullet_blocks"
    # NAME: "kitchen"
ARGS: 
  # []
  - "debug"
  # - "make_failure_videos"
  # - "make_test_videos"
  # - "make_segmented_demo_videos"
  - "make_demo_videos" 
  # - "use_gui"

FLAGS:
  rgb_observation: True
  num_train_tasks: 5
  num_test_tasks: 5
  option_learner: no_learning # include all options by flagging no learning
  kitchen_use_perfect_samplers: True
  # bilevel_plan_without_sim: True
  # included_options: "HandPressButton"
  # stick_button_button_position: "only_bottom"
  # stick_button_button_position: "only_top"
  # excluded_predicates: "all"
  sesame_max_samples_per_step: 10
  min_perc_data_for_nsrt: 1
  segmenter: "option_changes"
  neural_gaus_regressor_max_itr: 50000
  video_fps: 20

  rgb_observation: True
  sesame_check_expected_atoms: False

START_SEED: 2
NUM_SEEDS: 1
...
