# Use VLM to propose predicates.
---
APPROACHES:
  learn_all:
    NAME: "oracle"
    FLAGS: []
ENVS:
  stick_button:
    NAME: "stick_button"
ARGS: 
  # []
  - "debug"
  # - "rgb_observation" # stick_button doesn't support rendering
  # - "make_failure_videos"
  # - "make_test_videos"
  # - "make_segmented_demo_videos"
  # - "make_demo_videos" 
  # - "use_gui"
FLAGS:
  num_train_tasks: 10
  num_test_tasks: 1
  option_learner: direct_bc # So it doesn' include all oracle options in init
                            # when including all options, should also include
                            # all predicates.
  included_options: "RobotPressButton"
  # stick_button_button_position: "only_bottom"
  # stick_button_button_position: "only_top"
  # bilevel_plan_without_sim: True
  excluded_predicates: "'Grasped,StickAboveButton'"
  sesame_max_samples_per_step: 100
  min_perc_data_for_nsrt: 1
  segmenter: "contacts"
  neural_gaus_regressor_max_itr: 50000
  vlm_model_name: "gpt-3.5-turbo-0125"
  timeout: 300
  pybullet_camera_width: 1674 
  pybullet_camera_height: 900
  video_fps: 20

START_SEED: 456
NUM_SEEDS: 1
...
