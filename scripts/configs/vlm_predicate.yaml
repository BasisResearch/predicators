# Use VLM to propose predicates.
---
APPROACHES:
  learn_all:
    NAME: "vlm_invention"
    FLAGS: []
ENVS:
  stick_button:
    NAME: "stick_button"
ARGS: 
  # []
  - "debug"
  # - "rgb_observation" # stick_button doesn't support rendering
  # - "make_segmented_demo_videos"
  # - "make_demo_videos" 
  # - "use_gui"
FLAGS:
  excluded_predicates: "'Grasped,StickAboveButton'"
  included_options: "RobotPressButton"
  sesame_max_samples_per_step: 100  # mainly to improve demo collection
  min_perc_data_for_nsrt: 1
  segmenter: "contacts"
  option_learner: direct_bc
  neural_gaus_regressor_max_itr: 50000
  vlm_model_name: "gpt-3.5-turbo-0125"
  num_train_tasks: 2
  timeout: 300
  pybullet_camera_width: 1674 
  pybullet_camera_height: 900

START_SEED: 456
NUM_SEEDS: 1
...
