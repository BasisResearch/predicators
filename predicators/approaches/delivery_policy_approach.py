"""An approach that implements a delivery-specific policy.

Example command line:
    python predicators/main.py --approach delivery_policy --seed 0 \
        --env pddl_easy_delivery_procedural_tasks
"""

from typing import Callable, cast

import numpy as np

from predicators.approaches import BaseApproach

from predicators.approaches.pg3_approach import PG3Approach, _PG3SearchOperator
from predicators.envs.pddl_env import _PDDLEnvState
from predicators.structs import Action, GroundAtom, State, Task

from typing import Callable, Dict, FrozenSet, Iterator, List, Optional, \
    Sequence, Set, Tuple
from typing import Type as TypingType
from predicators.structs import NSRT, Action, Box, Dataset, GroundAtom, \
    LDLRule, LiftedAtom, LiftedDecisionList, Object, ParameterizedOption, \
    Predicate, State, Task, Type, Variable, _GroundNSRT

import dill as pkl

from predicators.settings import CFG
from predicators import utils
from typing_extensions import TypeAlias
import logging

class DeliveryPolicyApproach(PG3Approach):
    """Implements a delivery-specific policy."""

    def __init__(self, initial_predicates: Set[Predicate],
                 initial_options: Set[ParameterizedOption], types: Set[Type],
                 action_space: Box, train_tasks: List[Task]) -> None:
        super().__init__(initial_predicates, initial_options, types,
                         action_space, train_tasks)
        if CFG.policy:
            with open(CFG.policy, "rb") as f:
                self._current_ldl = pkl.load(f)
        else:
            self._current_ldl = LiftedDecisionList([])
    
    def _learn_ldl_from_initial_state(self, online_learning_cycle: Optional[int], initial_ldl: LiftedDecisionList) -> None:
        """Learn a lifted decision list policy after setting initial policy."""
        # Set up a search over LDL space.
        _S: TypeAlias = LiftedDecisionList
        # An "action" here is a search operator and an integer representing the
        # count of successors generated by that operator.
        _A: TypeAlias = Tuple[_PG3SearchOperator, int]

        # Create the PG3 search operators.
        search_operators = self._create_search_operators()

        # The heuristic is what distinguishes PG3 from baseline approaches.
        heuristic = self._create_heuristic()

        # Initialize the search with an empty LDL.
        initial_state = initial_ldl

        def get_successors(ldl: _S) -> Iterator[Tuple[_A, _S, float]]:
            for op in search_operators:
                for i, child in enumerate(op.get_successors(ldl)):
                    yield (op, i), child, 1.0  # cost always 1

        if CFG.pg3_search_method == "gbfs":
            # Terminate only after max expansions.
            path, _ = utils.run_gbfs(
                initial_state=initial_state,
                check_goal=lambda _: False,
                get_successors=get_successors,
                heuristic=heuristic,
                max_expansions=CFG.pg3_gbfs_max_expansions,
                lazy_expansion=True)

        elif CFG.pg3_search_method == "hill_climbing":
            # Terminate when no improvement is found.
            path, _, _ = utils.run_hill_climbing(
                initial_state=initial_state,
                check_goal=lambda _: False,
                get_successors=get_successors,
                heuristic=heuristic,
                early_termination_heuristic_thresh=0,
                enforced_depth=CFG.pg3_hc_enforced_depth)

        else:
            raise NotImplementedError("Unrecognized pg3_search_method "
                                      f"{CFG.pg3_search_method}.")

        # Save the best seen policy.
        self._current_ldl = path[-1]
        logging.info(f"Keeping best policy:\n{self._current_ldl}")
        save_path = utils.get_approach_save_path_str()
        with open(f"{save_path}_{online_learning_cycle}.ldl", "wb") as f:
            pkl.dump(self._current_ldl, f)

    def _learn_ldl(self, online_learning_cycle: Optional[int]) -> None:
        """Learn a lifted decision list policy."""
        self._learn_ldl_from_initial_state(online_learning_cycle, self._current_ldl)

    @classmethod
    def get_name(cls) -> str:
        return "delivery_policy"