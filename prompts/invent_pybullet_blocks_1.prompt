You are an expert AI researcher tasked with inventing task-specific state abstraction predicates for effective and efficient robotic planning.

I will describe the API you should use for writing predicates and the environment the robot is in.
# API for Defining Predicates
Class definitions for `Predicate` and `State` are:
```python
class RawState:
    """
    A class representing the raw visual state of the world

    Attributes:
    -----------
    labeled_image : Image
        An observation of the state annotated with a unique label for each object.

    Methods:
    --------
    crop_to_objects(self, objects: Collection[Object],
                    left_margin: int = 5, lower_margin: int=10, 
                    right_margin: int=10, top_margin: int=5) -> Image:
        Crops the labeled image to only focus on the objects in the input.
    get(self, obj: Object, feature_name: str) -> Any:
        Looks up an object feature by name and returns the feature value.
    get_objects(self, object_type: Type) -> List[Object]:
        Returns objects of the given type.
    evaluate_simple_assertion(assertion: str, image: Image) -> bool:
        Evaluate a simple assertion about an image..
    """
    def crop_to_objects(self, objects: Collection[Object],
                        left_margin: int = 5,
                        lower_margin: int=10, 
                        right_margin: int=10, 
                        top_margin: int=5) -> Image:
        """
        Crop the labeled_image to only include the specified objects, with 
        optional margins around the objects.

        Parameters:
        -----------
        objects : Collection[Object]
            The objects to include in the cropped image.
        left_margin, lower_margin, right_margin, top_margin : int, optional
            The left, lower, right, and top margin to include in the cropped 
            image (default is 5, 10, 10 and 5).

        Returns:
        --------
        Image
            The cropped image.
        Examples:
        ---------
        >>> # An example for predicate On
        >>> def _On_NSP_holds(state: RawState, objects: Sequence[Object])\
        >>>     -> bool:
        >>>     '''
        >>>     Determine if the first block in objects is directly on top of 
        >>>     the second block 
        >>>     '''
        >>>     block1, block2 = objects
        >>>     ...
        >>>     # Crop the scene image to the smallest bounding box that include both objects.
        >>>     attention_image = state.crop_to_objects([block1, block2])
        >>>     return state.evaluate_simple_assertion(
        >>>         f"{block1_name} is directly on top of {block2_name} with no blocks in between.", attention_image)
        >>>
        >>> # An example for predicate OnTable
        >>> def _OnTable_NSP_holds(state: RawState, objects:Sequence[Object]) ->\
        >>>         bool:
        >>>     '''Determine if the block is directly resting on the table's 
        >>>     surface.
        >>>     '''
        >>>     apple, = objects
        >>>     apple_name = apple.id_name
        >>>     
        >>>     # Crop the scene image to the smallest bounding box that include both objects.
        >>>     # We know there is only one table in this environment.
        >>>     table = state.get_objects(_table_type)[0]
        >>>     table_name = table.id_name
        >>>     attention_image = state.crop_to_objects([apple, table])

        >>>     return state.evaluate_simple_assertion(
        >>>         f"{apple_name} is directly resting on {table_name}'s surface.",
        >>>         attention_image)
        """

    def get(self, obj: Object, feature_name: str) -> Any:
        """
        Look up an object feature by name.

        Parameters:
        -----------
        obj : Object
            The object whose feature value is to be retrieved.
        feature_name : str
            The name of the feature to be retrieved.

        Returns:
        --------
        Any
            The value of the specified feature for the given object.
        
        Example:
        ---------
        >>> # An example for predicate WristBent
        >>> _robot_type = Type("robot", ["x", "y", "tilt", "wrist", "fingers"])
        >>> def _WristBent_holds(state: State, objects: Sequence[Object]
        >>>                     ) -> bool:
        >>>     robot, = objects
        >>>     return state.get(robot, "wrist") >= 0.5
        >>> _WristBent = NSPredicate("WristBent", [_robot_type], _WristBent_holds)
        >>>
        >>> # An example for classifying Covers
        >>> def _Covers_NSP_holds(state: State, objects: Sequence[Object]
        >>>                         ) -> bool:
        >>>     '''
        >>>     Determine if the block is covering (directly on top of) the target 
        >>>     region.
        >>>     '''
        >>>     block, target = objects
        >>>
        >>>     # Necessary but not sufficient condition for covering: no part of the 
        >>>     # target region is outside the block.
        >>>     if state.get(target, "bbox_left") < state.get(block, "bbox_left") or\
        >>>        state.get(target, "bbox_right") > state.get(block, "bbox_right"):
        >>>         return False
        >>>     ...
        >>>     return state.evaluate_simple_assertion(...)
        """

    def get_objects(self, object_type: Type) -> List[Object]:
        """
        Return objects of the given type in the state

        Parameters:
        -----------
        object_type : Type
            The type of the objects to be retrieved.

        Returns:
        --------
        List[Object]
            A list of objects of the specified type, in the order they are 
            iterated over in the state.

        Examples:
        ---------
        >>> def _robot_hand_above_cup(state: State, cup: Object) -> bool:
        >>>     ...
        >>>
        >>> def _HandNotAboveCup_holds(state: State,
        >>>                            objects: Sequence[Object]) -> bool:
        >>>     for cup in state.get_objects(_cup_type):
        >>>         if _robot_hand_above_cup(state, cup):
        >>>             return False
        >>>     return True
        >>> _HandNotAboveCup = NSPredicate("HandNotAboveCup", [], 
        >>>                              _HandNotAboveCup_holds)
        """

    def evaluate_simple_assertion(self, assertion: str, image: Image) -> bool:
        """
        A function that takes a simple assertion as a string and 
        an image as input, and returns a boolean indicating whether the 
        assertion holds true for the image according to the VLM.

        The assertion should be clear, unambiguous, and relatively simple, and 
        the image should have been cropped to only the relavant objects.

        Parameters:
        -----------
        assertion : str
            The assertion to be evaluated. This should be a clear, unambiguous, and 
            relatively simple statement about the image.

        image : Image
            The image for which the assertion is to be evaluated.

        Returns:
        --------
        bool
            True if the VLM determines that the assertion holds true for the image, 
            False otherwise.
        
        Examples:
        ---------
        >>> # An example for predicate Open
        >>> ...
        >>> return state.evaluate_simple_assertion(f"{door_name} is open", attention_image)

        >>> # An example for predicate CupOnTable
        >>> ...
        >>> return state.evaluate_simple_assertion(f"{cup_name} is resting on {shelf_name}", attention_image)

        >>> # An example for predicate CupFilled
        >>> ...
        >>> return state.evaluate_simple_assertion(f"{cup_name} is filled with liquid", attention_image)

        >>> # An example for predicate PluggedIn
        >>> ...
        >>> return state.evaluate_simple_assertion(f"{coffee_machine_name} is plugged into a socket", attention_image)
        """

class NSPredicate:
    """
    A class representing a predicate, a classifier that characterizes properties 
    of states in the context of AI task planning.
    A predicate is a function that takes a state and a sequence of objects as 
    input, and returns a boolean value indicating whether a certain property 
    holds for those objects in that state.

    Parameters:
    -----------
    name : str
        The name of the predicate.

    types : Sequence[Type]
        The types of the objects that the predicate applies to. This sequence 
        length should match the number of objects passed to the classifier. Each
        type corresponds one-to-one with an object in the sequence. 

    _classifier : Callable[[State, Sequence[Object]], bool]
        The classifier function for the predicate. It takes a state and a
        sequence of objects as input, and returns a boolean value. The sequence
        of objects should correspond one-to-one with the 'types' attribute. The 
        classifier returns True if the predicate holds for those objects in that 
        state, and False otherwise.
    """    
```


# The Environment
The environment includes the following object-type variables:
```python
_block_type = Type("block", ["pose_x", "pose_y", "pose_z", "bbox_left", "bbox_right", "bbox_upper", "bbox_lower"])
_robot_type = Type("robot", ["pose_x", "pose_y", "pose_z", "fingers", "bbox_right", "bbox_upper", "bbox_lower"])
_table_type = Type("table", ["bbox_right", "bbox_upper", "bbox_lower"])
```


The existing set of predicates are:
{'On(?x:block, ?y:block)', 'OnTable(?x:block)'}

Predicate OnTable(?x) is defined by:
```python
def _OnTable_NSP_holds(state: RawState, objects:Sequence[Object]) ->\
        bool:
    '''Determine if the block in objects is directly resting on the table's 
    surface in the scene image, using both rules and VLMs.
    It first identifies the table in the scene, then crops the scene image 
    to the smallest bounding box that includes both the block and the table, 
    and finally evaluates a simple assertion about their relative positions.

    Parameters:
    -----------
    state : RawState
        The current state of the world, represented as an image.
    objects : Sequence[Object]
        A sequence containing a single block whose relationship with the 
        table is to be determined.

    Returns:
    --------
    bool
        True if the block is directly resting on the table's surface, False 
        otherwise.
    '''
    block, = objects
    block_name = block.id_name

    # Crop the image to the smallest bounding box that include both objects.
    # We know there is only one table in this environment.
    table = state.get_objects(_table_type)[0]
    table_name = table.id_name
    attention_image = state.crop_to_objects([block, table])

    return state.evaluate_simple_assertion(
        f"{block_name} is directly resting on {table_name}'s surface.",
        attention_image)
_OnTable_NSP = NSPredicate("OnTable", [_block_type],
                                    _OnTable_NSP_holds)
```

Predicate On(?x, ?y) is defined by:
```python
def _On_NSP_holds(state: RawState, objects: Sequence[Object]) -> bool:
    '''
    Determine if the first block in objects is directly on top of the second 
    block in the scene image, by using a combination of rules and VLMs.

    It first checks if the blocks are the same or if they are far away from 
    each other. If neither condition is met, it crops the scene image to the 
    smallest bounding box that includes both blocks and evaluates a simple 
    assertion about their relative positions.

    Parameters:
    -----------
    state : RawState
        The current state of the world, represented as an image.
    objects : Sequence[Object]
        A sequence of two blocks whose relationship is to be determined. The 
        first block is the one that is potentially on top.

    Returns:
    --------
    bool
        True if the first block is directly on top of the second block with 
        no blocks in between, False otherwise.
    '''

    block1, block2 = objects
    block1_name, block2_name = block1.id_name, block2.id_name

    # Heuristics: we know a block can't be on top of it
    if block1_name == block2_name:
        return False

    # repeat the above
    if state.get(block1, "bbox_lower") < state.get(block2, "bbox_lower")or\
       state.get(block1, "bbox_left") > state.get(block2, "bbox_right") or\
       state.get(block1, "bbox_right") < state.get(block2, "bbox_left") or\
       state.get(block1, "bbox_upper") < state.get(block2, "bbox_upper") or\
       state.get(block1, "pose_z") < state.get(block2, "pose_z"):
        return False

    # Crop the scene image to the smallest bounding box that include both
    # objects.
    attention_image = state.crop_to_objects([block1, block2])

    return state.evaluate_simple_assertion(
        f"{block1_name} is directly on top of {block2_name} with no blocks"+
         " in between.", attention_image)
_On_NSP = NSPredicate("On", [_block_type, _block_type],
                                    _On_NSP_holds)
```


The robot tried to excute its options and got the following results:
Option Stack(robot1:robot, block5:block) was applied on 136 states and *successfully* executed on 1/136 states (ground truth positive states).
They are:
  state_58 with additional info:
  {'block3:block',
   'block4:block',
   'block5:block',
   'block6:block',
   'robot1:robot': {'fingers': 0.0},
   'table2:table'}

Option Stack(robot1:robot, block5:block) was applied on 136 states and *failed* to executed on 135/136 states (ground truth negative states).
To list {max_num_examples}:
  state_0 with additional info:
  {'block3:block',
   'block4:block',
   'block5:block',
   'block6:block',
   'robot1:robot': {'fingers': 1.0},
   'table2:table'}

Option Stack(robot1:robot, block4:block) was applied on 162 states and *successfully* executed on 1/162 states (ground truth positive states).
They are:
  state_82 with additional info:
  {'block3:block',
   'block4:block',
   'block5:block',
   'robot1:robot': {'fingers': 0.0},
   'table2:table'}

Option Stack(robot1:robot, block4:block) was applied on 162 states and *failed* to executed on 161/162 states (ground truth negative states).
To list {max_num_examples}:
  state_0 with additional info:
  {'block3:block',
   'block4:block',
   'block5:block',
   'block6:block',
   'robot1:robot': {'fingers': 1.0},
   'table2:table'}

Option Pick(robot1:robot, block6:block) was applied on 2 states and *successfully* executed on 2/2 states (ground truth positive states).
To list {max_num_examples}:
  state_20 with additional info:
  {'block3:block',
   'block4:block',
   'block5:block',
   'block6:block',
   'robot1:robot': {'fingers': 1.0},
   'table2:table'}

Option Pick(robot1:robot, block5:block) was applied on 14 states and *successfully* executed on 6/14 states (ground truth positive states).
To list {max_num_examples}:
  state_68 with additional info:
  {'block3:block',
   'block4:block',
   'block5:block',
   'robot1:robot': {'fingers': 1.0},
   'table2:table'}

Option Pick(robot1:robot, block5:block) was applied on 14 states and *failed* to executed on 8/14 states (ground truth negative states).
To list {max_num_examples}:
  state_15 with additional info:
  {'block3:block',
   'block4:block',
   'block5:block',
   'block6:block',
   'robot1:robot': {'fingers': 1.0},
   'table2:table'}

Option Pick(robot1:robot, block4:block) was applied on 24 states and *successfully* executed on 2/24 states (ground truth positive states).
To list {max_num_examples}:
  state_94 with additional info:
  {'block3:block',
   'block4:block',
   'block5:block',
   'robot1:robot': {'fingers': 1.0},
   'table2:table'}

Option Pick(robot1:robot, block4:block) was applied on 24 states and *failed* to executed on 22/24 states (ground truth negative states).
To list {max_num_examples}:
  state_37 with additional info:
  {'block3:block',
   'block4:block',
   'block5:block',
   'block6:block',
   'robot1:robot': {'fingers': 1.0},
   'table2:table'}

Option PutOnTable(robot1:robot) was applied on 231 states and *successfully* executed on 6/231 states (ground truth positive states).
To list {max_num_examples}:
  state_102 with additional info:
  {'block3:block',
   'block4:block',
   'block5:block',
   'robot1:robot': {'fingers': 0.0},
   'table2:table'}

Option PutOnTable(robot1:robot) was applied on 231 states and *failed* to executed on 225/231 states (ground truth negative states).
To list {max_num_examples}:
  state_0 with additional info:
  {'block3:block',
   'block4:block',
   'block5:block',
   'block6:block',
   'robot1:robot': {'fingers': 1.0},
   'table2:table'}


Your task is to identify the key differences between the positive and negative states for each option, and propose predicates that can be used to differentiate between positive and negative states. Make sure they don't repeat the existing predicates.

Propose predicates in paragraphs as follows. For each proposal:
- Identify which differentiating property from above it corresponds to.
- Define predicate in a Python block as follows:
```python
def classifier(state: State, objects: Sequence[Object]) -> bool:
    # Implement the boolean classifier function here
    ...
    
name: str = ... # Define the predicate name here
param_types: Sequence[Type] = ... # A list of object-type variables for the predicate, using the ones defined in the environment<predicate_name> = NSPredicate(name, param_types, classifier)
```

In writing the proposals, ensure the following:
- **When defining classifier functions, first use rules based on object features to identify scenarios where the predicate is *clearly* False (the robot can't be holding anything if its hand is open). Then, use the `evaluate_simple_assertion` method to address potential remaining cases.** Reference the format of predefined predicates;
- Use only object-type variables defined in the environment when defining  `param_types`.
- The proposed predicates don't overlap with any of the existing predicates.
- Don't use any undefined constants;
- The object-feature names used are consistent with those available in state and object type definitions;
- Strictly adhere to the type hints in the predicate definition template.
- Don't need to write out the new operators.
- Make use of the helper methods such as `evaluate_simple_assertion`, `crop_to_objects`, `get` and `get_objects` or other defined helper functions.