"""Analyzing skeleton length (relative to demos) generated by task planning as
a function of the number of predicates included."""

from typing import Tuple, FrozenSet, List
import functools
import os
import numpy as np
from numpy.typing import NDArray
import matplotlib.pyplot as plt
from predicators.src.datasets import create_dataset
from predicators.src.envs import create_env
from predicators.src.approaches import ApproachFailure, ApproachTimeout
from predicators.src import utils
from predicators.src.settings import CFG
from predicators.src.planning import task_plan, task_plan_grounding
from predicators.src.structs import Dataset, Task, Predicate
from predicators.src.nsrt_learning import segment_trajectory, \
    learn_strips_operators

ENV_NAMES = ["cover", "cover_regrasp", "blocks", "painting"]

SEEDS = list(range(10))


@functools.lru_cache(maxsize=None)
def _setup_data_for_env(env_name: str,
                        seed: int) -> Tuple[List[Task], Dataset, List[int]]:
    # Create data for this environment and seed.
    utils.reset_config({"seed": seed, "env": env_name})
    env = create_env(env_name)
    env.seed(seed)
    train_tasks = env.get_train_tasks()
    dataset = create_dataset(env, train_tasks)
    assert all(traj.is_demo for traj in dataset.trajectories)
    demo_skeleton_lengths = [
        utils.num_options_in_action_sequence(t.actions)
        for t in dataset.trajectories
    ]
    return (train_tasks, dataset, demo_skeleton_lengths)


@functools.lru_cache(maxsize=None)
def _compute_skeleton_length_errors(
        env_name: str,
        seed: int,
        frozen_predicate_set: FrozenSet[Predicate],
        max_skeletons: int = 8,
        timeout: float = 10,
        error_upper_bound: int = 100) -> NDArray[np.int32]:
    current_predicate_set = set(frozen_predicate_set)
    # Load cached data for this env and seed.
    train_tasks, dataset, demo_skeleton_lengths = _setup_data_for_env(
        env_name, seed)
    # Learn operators.
    atom_dataset = utils.create_ground_atom_dataset(dataset.trajectories,
                                                    current_predicate_set)
    segments = [
        seg for traj in atom_dataset for seg in segment_trajectory(traj)
    ]
    pnads = learn_strips_operators(segments, verbose=False)
    strips_ops = [pnad.op for pnad in pnads]
    option_specs = [pnad.option_spec for pnad in pnads]
    # For each train task / demo, run task planning, and measure the error
    # in skeleton length relative to the demos.
    skeleton_length_errors = []  # shape (num tasks, max skeletons)
    for traj, demo_len in zip(dataset.trajectories, demo_skeleton_lengths):
        # Run task planning.
        train_task = train_tasks[traj.train_task_idx]
        init_atoms = utils.abstract(traj.states[0], current_predicate_set)
        objects = set(traj.states[0])
        ground_nsrts, reachable_atoms = task_plan_grounding(
            init_atoms, objects, strips_ops, option_specs)
        heuristic = utils.create_task_planning_heuristic(
            CFG.task_planning_heuristic, init_atoms, train_task.goal,
            ground_nsrts, current_predicate_set, objects)
        generator = task_plan(init_atoms, train_task.goal, ground_nsrts,
                              reachable_atoms, heuristic, seed, timeout,
                              max_skeletons)
        task_skeleton_length_errors = []
        try:
            for plan_skeleton, _, _ in generator:
                error = abs(len(plan_skeleton) - demo_len)
                task_skeleton_length_errors.append(error)
        except (ApproachTimeout, ApproachFailure):
            # Use an upper bound on the error.
            num_missing = max_skeletons - len(task_skeleton_length_errors)
            for _ in range(num_missing):
                task_skeleton_length_errors.append(error_upper_bound)
        skeleton_length_errors.append(task_skeleton_length_errors)
    errors_arr = np.array(skeleton_length_errors, dtype=np.int32)
    assert errors_arr.shape == (len(train_tasks), max_skeletons)
    return errors_arr


def _order_predicate_sets(
        env_name: str,
        seed: int,
        max_skeletons: int = 8,
        timeout: float = 10,
        error_upper_bound: int = 100) -> Tuple[FrozenSet[Predicate], ...]:
    utils.reset_config({"seed": seed, "env": env_name})
    env = create_env(env_name)
    oracle_predicates = env.predicates
    # Starting with an empty predicate set (plus goal predicates),
    # build up to the oracle predicate set, adding one predicate at a time.
    current_predicate_set = frozenset(env.goal_predicates)
    order = [current_predicate_set]
    num_candidates = len(oracle_predicates) - len(current_predicate_set)
    for _ in range(num_candidates):
        # Evaluate each possible next candidate predicate set and keep the
        # best one.
        best_next_predicate_set: FrozenSet[Predicate] = frozenset()
        best_score = np.inf
        for next_predicate in oracle_predicates - current_predicate_set:
            next_predicate_set = current_predicate_set | {next_predicate}
            print("Evaluating predicate set:", next_predicate_set)
            next_predicate_set_result = _compute_skeleton_length_errors(
                env_name,
                seed,
                next_predicate_set,
                max_skeletons=max_skeletons,
                timeout=timeout,
                error_upper_bound=error_upper_bound)
            next_predicate_set_score = _score_result(next_predicate_set_result)
            if next_predicate_set_score < best_score:
                best_next_predicate_set = next_predicate_set
                best_score = next_predicate_set_score
        assert not np.isinf(best_score)
        print("Found next best predicate set:")
        print(best_next_predicate_set)
        current_predicate_set = best_next_predicate_set
        order.append(current_predicate_set)
    assert current_predicate_set == oracle_predicates
    return tuple(order)


def _score_result(result: NDArray[np.int32]) -> float:
    """Min over skeleton idx and mean over train tasks."""
    return result.min(axis=1).mean()


def _create_predicate_labels(
        predicate_set_order: Tuple[FrozenSet[Predicate], ...]) -> List[str]:
    labels = [", ".join(p.name for p in predicate_set_order[0])]
    for i in range(len(predicate_set_order) - 1):
        new_predicates = predicate_set_order[i + 1] - predicate_set_order[i]
        assert len(new_predicates) == 1
        new_predicate = next(iter(new_predicates))
        labels.append(f"+{new_predicate.name}")
    return labels


def _create_heatmap(env_results: NDArray[np.int32], env_name: str,
                    predicate_set_order: Tuple[FrozenSet[Predicate],
                                               ...], outfile: str) -> None:
    # Env results shape is (seed, predicate set, task, skeleton idx).
    # Reorganize into heatmap array of shape (predicate set, skeleton idx)
    # by averaging out seed and task.
    heatmap_arr = np.mean(env_results, axis=(0, 2))
    num_predicate_sets, num_skeletons = heatmap_arr.shape
    assert num_predicate_sets == len(predicate_set_order)
    labels = _create_predicate_labels(predicate_set_order)

    fig, ax = plt.subplots()
    ax.imshow(heatmap_arr)
    ax.set_xticks(np.arange(num_skeletons))
    ax.set_yticks(np.arange(num_predicate_sets), labels=labels)
    for i in range(num_skeletons):
        for j in range(num_predicate_sets):
            ax.text(i,
                    j,
                    f"{heatmap_arr[j, i]:.2f}",
                    ha="center",
                    va="center",
                    color="w")

    ax.set_title(f"{env_name.capitalize()}: Skeleton Length Errors")
    ax.set_xlabel("Skeleton Index")
    fig.tight_layout()
    plt.savefig(outfile)
    print(f"Wrote out to {outfile}.")


def _create_plot(env_results: NDArray[np.int32], env_name: str,
                 predicate_set_order: Tuple[FrozenSet[Predicate],
                                            ...], outfile: str) -> None:
    # Env results shape is (seed, predicate set, task, skeleton idx).
    # Reorganize into array of shape (predicate set,) by scoring each seed's
    # result and then averaging out seed.
    arr = np.mean([[_score_result(r) for r in seed_rs]
                   for seed_rs in env_results],
                  axis=0)
    num_predicate_sets, = arr.shape
    assert num_predicate_sets == len(predicate_set_order)
    labels = _create_predicate_labels(predicate_set_order)

    fig, ax = plt.subplots()
    ax.plot(np.arange(num_predicate_sets), arr)

    ax.set_xticks(np.arange(num_predicate_sets), labels=labels)
    plt.setp(ax.get_xticklabels(),
             rotation=45,
             ha="right",
             rotation_mode="anchor")
    ax.set_title(f"{env_name.capitalize()}: Min Skeleton Length Errors")
    ax.set_ylabel("Min Skeleton Length Error")
    fig.tight_layout()
    plt.savefig(outfile)
    print(f"Wrote out to {outfile}.")


def _main() -> None:
    outdir = os.path.join(os.path.dirname(os.path.realpath(__file__)),
                          "results")
    os.makedirs(outdir, exist_ok=True)

    for env_name in ENV_NAMES:
        # First determine the predicate sets that we want to use for this env.
        # Do this by hill climbing over all seeds and taking the mode.
        # Cache everything to avoid redundant computation.
        predicate_set_orders = [
            _order_predicate_sets(env_name, seed) for seed in SEEDS
        ]
        predicate_set_order = max(predicate_set_orders,
                                  key=predicate_set_orders.count)
        # Now create the per-seed results that we will actually plot.
        env_results = []
        for seed in SEEDS:
            seed_results = [
                _compute_skeleton_length_errors(env_name, seed, p)
                for p in predicate_set_order
            ]
            env_results.append(seed_results)
        results_arr = np.array(env_results, dtype=np.int32)
        outfile = os.path.join(outdir, f"skeleton_len_heatmap_{env_name}.png")
        _create_heatmap(results_arr, env_name, predicate_set_order, outfile)
        outfile = os.path.join(outdir, f"skeleton_len_plot_{env_name}.png")
        _create_plot(results_arr, env_name, predicate_set_order, outfile)


if __name__ == "__main__":
    _main()
