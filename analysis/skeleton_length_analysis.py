"""Analyzing skeleton length (relative to demos) generated by task planning as
a function of the number of predicates included."""

from typing import Sequence, Set
import os
import numpy as np
from numpy.typing import NDArray
import matplotlib.pyplot as plt
from predicators.src.datasets import create_dataset
from predicators.src.envs import create_env
from predicators.src.approaches import ApproachFailure, ApproachTimeout
from predicators.src import utils
from predicators.src.settings import CFG
from predicators.src.planning import task_plan, task_plan_grounding
from predicators.src.structs import Dataset, Task, Predicate
from predicators.src.nsrt_learning import segment_trajectory, \
    learn_strips_operators

ENV_NAMES = ["cover", "blocks", "painting"]

SEEDS = list(range(10))


def _run_analysis_for_env(env_name: str,
                          seed: int,
                          max_skeletons: int = 8,
                          timeout: float = 10,
                          error_upper_bound: int = 100) -> NDArray[np.int32]:
    # Create data for this environment and seed.
    utils.reset_config({"seed": seed, "env": env_name})
    env = create_env(env_name)
    env.seed(seed)
    train_tasks = env.get_train_tasks()
    dataset = create_dataset(env, train_tasks)
    assert [t.train_task_idx for t in dataset.trajectories] == \
        list(range(len(train_tasks)))
    demo_skeleton_lengths = [
        utils.num_options_in_action_sequence(t.actions)
        for t in dataset.trajectories
    ]
    # Get the oracle predicates.
    oracle_predicates = env.predicates
    # Starting with an empty predicate set (plus goal predicates),
    # build up to the oracle predicate set, adding one predicate at a time.
    current_predicate_set = set(env.goal_predicates)
    num_candidates = len(oracle_predicates) - len(current_predicate_set)
    # All results, final shape (num candidates + 1, num tasks, max skeletons).
    all_results = []
    # Start by evaluating the initial current_predicate set.
    initial_predicate_set_result = _compute_skeleton_length_errors(
        dataset,
        train_tasks,
        current_predicate_set,
        demo_skeleton_lengths,
        seed,
        max_skeletons=max_skeletons,
        timeout=timeout,
        error_upper_bound=error_upper_bound)
    all_results.append(initial_predicate_set_result)
    for _ in range(num_candidates):
        # Evaluate each possible next candidate predicate set and keep the
        # best one.
        best_next_predicate_set = set()
        # This is just for type checking; it will get overwritten.
        best_next_predicate_set_result = initial_predicate_set_result
        best_score = np.inf
        for next_predicate in oracle_predicates - current_predicate_set:
            next_predicate_set = current_predicate_set | {next_predicate}
            print("Evaluating predicate set:", next_predicate_set)
            next_predicate_set_result = _compute_skeleton_length_errors(
                dataset,
                train_tasks,
                next_predicate_set,
                demo_skeleton_lengths,
                seed,
                max_skeletons=max_skeletons,
                timeout=timeout,
                error_upper_bound=error_upper_bound)
            next_predicate_set_score = _score_result(next_predicate_set_result)
            if next_predicate_set_score < best_score:
                best_next_predicate_set = next_predicate_set
                best_next_predicate_set_result = next_predicate_set_result
                best_score = next_predicate_set_score
        assert not np.isinf(best_score)
        print("Found next best predicate set:")
        print(best_next_predicate_set)
        current_predicate_set = best_next_predicate_set
        all_results.append(best_next_predicate_set_result)
    assert current_predicate_set == oracle_predicates
    all_results_arr = np.array(all_results, dtype=np.int32)
    assert all_results_arr.shape == (num_candidates + 1, len(train_tasks),
                                     max_skeletons)
    return all_results_arr


def _score_result(result: NDArray[np.int32]) -> float:
    """Currently using average over skeletons and demos."""
    return result.mean()


def _compute_skeleton_length_errors(
        dataset: Dataset,
        train_tasks: Sequence[Task],
        current_predicate_set: Set[Predicate],
        demo_skeleton_lengths: Sequence[int],
        seed: int,
        max_skeletons: int = 8,
        timeout: float = 10,
        error_upper_bound: int = 100) -> NDArray[np.int32]:
    # Learn operators.
    atom_dataset = utils.create_ground_atom_dataset(dataset.trajectories,
                                                    current_predicate_set)
    segments = [
        seg for traj in atom_dataset for seg in segment_trajectory(traj)
    ]
    pnads = learn_strips_operators(segments, verbose=False)
    strips_ops = [pnad.op for pnad in pnads]
    option_specs = [pnad.option_spec for pnad in pnads]
    # For each train task / demo, run task planning, and measure the error
    # in skeleton length relative to the demos.
    skeleton_length_errors = []  # shape (num tasks, max skeletons)
    for train_task, demo_len in zip(train_tasks, demo_skeleton_lengths):
        # Run task planning.
        init_atoms = utils.abstract(train_task.init, current_predicate_set)
        objects = set(train_task.init)
        ground_nsrts, reachable_atoms = task_plan_grounding(
            init_atoms, objects, strips_ops, option_specs)
        heuristic = utils.create_task_planning_heuristic(
            CFG.task_planning_heuristic, init_atoms, train_task.goal,
            ground_nsrts, current_predicate_set, objects)
        generator = task_plan(init_atoms, train_task.goal, ground_nsrts,
                              reachable_atoms, heuristic, seed, timeout,
                              max_skeletons)
        task_skeleton_length_errors = []
        try:
            for plan_skeleton, _, _ in generator:
                error = abs(len(plan_skeleton) - demo_len)
                task_skeleton_length_errors.append(error)
        except (ApproachTimeout, ApproachFailure):
            # Use an upper bound on the error.
            num_missing = max_skeletons - len(task_skeleton_length_errors)
            for _ in range(num_missing):
                task_skeleton_length_errors.append(error_upper_bound)
        skeleton_length_errors.append(task_skeleton_length_errors)
    errors_arr = np.array(skeleton_length_errors, dtype=np.int32)
    assert errors_arr.shape == (len(train_tasks), max_skeletons)
    return errors_arr


def _create_heatmap(env_results: NDArray[np.int32], env_name: str,
                    outfile: str) -> None:
    # Env results shape is (seed, predicate set, task, skeleton idx).
    # Reorganize into heatmap array of shape (predicate set, skeleton idx)
    # by averaging out seed and task.
    heatmap_arr = np.mean(env_results, axis=(0, 2))
    num_predicate_sets, num_skeletons = heatmap_arr.shape

    fig, ax = plt.subplots()
    ax.imshow(heatmap_arr.T, origin='lower')
    ax.set_xticks(np.arange(num_predicate_sets))
    ax.set_yticks(np.arange(num_skeletons))
    for i in range(num_skeletons):
        for j in range(num_predicate_sets):
            ax.text(j,
                    i,
                    heatmap_arr[j, i],
                    ha="center",
                    va="center",
                    color="w")

    ax.set_title(f"{env_name.capitalize()}: Skeleton Length Errors")
    ax.set_xlabel("Num Non-Goal Predicates Included")
    ax.set_ylabel("Min Skeleton Length Error")
    fig.tight_layout()
    plt.savefig(outfile)
    print(f"Wrote out to {outfile}.")


def _create_plot(env_results: NDArray[np.int32], env_name: str,
                 outfile: str) -> None:
    # Env results shape is (seed, predicate set, task, skeleton idx).
    # Reorganize into array of shape (predicate set,) by minning over skeleton
    # idx and averaging out seed and task.
    arr = np.mean(np.min(env_results, axis=3), axis=(0, 2))  # type: ignore
    num_predicate_sets, = arr.shape

    fig, ax = plt.subplots()
    ax.plot(np.arange(num_predicate_sets), arr)

    ax.set_xticks(np.arange(num_predicate_sets))
    ax.set_title(f"{env_name.capitalize()}: Min Skeleton Length Errors")
    ax.set_xlabel("Num Non-Goal Predicates Included")
    ax.set_ylabel("Skeleton Index")
    fig.tight_layout()
    plt.savefig(outfile)
    print(f"Wrote out to {outfile}.")


def _main() -> None:
    for env_name in ENV_NAMES:
        env_results = []
        for seed in SEEDS:
            seed_results = _run_analysis_for_env(env_name, seed)
            env_results.append(seed_results)
        env_results_arr = np.array(env_results, dtype=np.int32)
        # outfile = os.path.join("results",
        #                        f"skeleton_len_heatmap_{env_name}.png")
        # _create_heatmap(env_results_arr, env_name, outfile)
        outfile = os.path.join("results", f"skeleton_len_plot_{env_name}.png")
        _create_plot(env_results_arr, env_name, outfile)


if __name__ == "__main__":
    _main()
